# LLM ON LOCAL MACHINE 
You can Download it from Hugging face </br>
till 1st commit no use of .json file </br>
Model: tinyllama-1.1b-chat-v1.0.Q4_K_M </br>
Engine : Llama.cpp-master </br>
build: Llama.cpp-master\build\release\Llama-run.exe </br>
